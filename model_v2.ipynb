{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCk+511awWwHW2fgzje82F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaredLevi18/Stock-market-predictor./blob/main/model_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pRVYWcPqLkjk"
      },
      "outputs": [],
      "source": [
        "! pip install alpha_vantage -q  # Python module to get stock data/cryptocurrencies from the Alpha Vantage API"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from alpha_vantage.timeseries import TimeSeries"
      ],
      "metadata": {
        "id": "-kGC_AqML2R9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"alpha_vantage\":{\n",
        "        \"key\": \"9D5258B5CTAEMGT4\",\n",
        "        \"symbol\": \"IBM\",\n",
        "        \"outputsize\": \"full\",\n",
        "        \"key_adjustedclose\": \"5. adjusted close\",\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"window_size\": 20,\n",
        "        \"train_split_size\": 0.80,\n",
        "    },\n",
        "    \"plots\": {\n",
        "        \"show_plots\": True,\n",
        "        \"xticks_interval\": 90,\n",
        "        \"color_actual\": \"#001f3f\",\n",
        "        \"color_train\": \"#3D9970\",\n",
        "        \"color_val\": \"#0074D9\",\n",
        "        \"color_pred_train\": \"#3D9970\",\n",
        "        \"color_pred_val\": \"#0074D9\",\n",
        "        \"color_pred_test\": \"#FF4136\",\n",
        "    },\n",
        "    \"model\":{\n",
        "        \"input_size\": 1, # only 1 because we're using the closing price\n",
        "        \"num_lstm_layers\": 2,\n",
        "        \"lstm_size\": 32,\n",
        "        \"dropout\": 0.2,\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"device\": \"cuda\",\n",
        "        \"batch_size\": 64,\n",
        "        \"num_epochs\": 100,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"scheduler_step_size\": 40,\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "m1AvRtdBNkWc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def download_data(config, plot=False):\n",
        "  ts = TimeSeries(key=config[\"alpha_vantage\"][\"key\"])\n",
        "  data, meta_data = ts.get_daily_adjusted(config[\"alpha_vantage\"][\"symbol\"], outputsize=config[\"alpha_vantage\"][\"outputsize\"])\n",
        "\n",
        "  data_date = [date for data in data.keys()]\n",
        "  data_date.reverse()\n",
        "\n",
        "  data_close_price = [float(data[date][config[\"alpha_vantage\"][\"key_adjusted_close\"]]) for date in data.keys()]\n",
        "  data_close_price.reverse()\n",
        "  data_close_price = np.array(data_close_price)\n",
        "\n",
        "  num_data_points = len(data_date)\n",
        "  display_date_range = \"from\" + data.date[0] + \"to\" + data_date[num_data_points - 1]\n",
        "  print(\"Number of data points\", num_data_points, display_date_range)\n",
        "\n",
        "  if plot:\n",
        "    fig = figure(figsize=(25,5), dpi=180)\n",
        "    fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "    plt.plot(data_date, data_close_price, color=config[\"plots\"][\"color_actual\"])\n",
        "    xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"] == 0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i == num_data_points-1) else None for i in range(num_data_points)]\n",
        "    x = np.arange(0,len(xticks))\n",
        "    plt.xticks(x, xtricks, rotation='vertical')\n",
        "    plt.title(\"Daily close price for\" + config[\"alpha_vantage\"][\"symbol\"] + \", \" + display_date_range)\n",
        "    plt.grid(b=None, which=\"major\", axis=\"y\", linestyle=\"--\")\n",
        "    plt.show()\n",
        "\n",
        "  return data_date, data_close_price, num_data_points, display_date_range\n",
        "\n",
        "data_date, data_close_price, num_data_points, display_date_range = download_data(config, plot=config[\"plots\"][\"show_plots\"])"
      ],
      "metadata": {
        "id": "ZSDLfh6J_MzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "a641296a-9148-4b48-bf77-b8a42b820ae0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8db71d79baae>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_close_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_data_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_date_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdata_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_close_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_data_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_date_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"plots\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"show_plots\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-8db71d79baae>\u001b[0m in \u001b[0;36mdownload_data\u001b[0;34m(config, plot)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha_vantage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_daily_adjusted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha_vantage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"symbol\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha_vantage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputsize\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdata_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/alpha_vantage/alphavantage.py\u001b[0m in \u001b[0;36m_format_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_format_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             call_response, data_key, meta_data_key = func(\n\u001b[0m\u001b[1;32m    219\u001b[0m                 self, *args, **kwargs)\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'json'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'pandas'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/alpha_vantage/alphavantage.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapikey_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_data_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/alpha_vantage/alphavantage.py\u001b[0m in \u001b[0;36m_handle_api_call\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Error Message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"Information\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_response\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreat_info_as_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Information\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"Note\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_response\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreat_info_as_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Note\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Thank you for using Alpha Vantage! This is a premium endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium endpoints"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing raw financial data\n",
        "class Normalizer():\n",
        "  def __init__(self):\n",
        "    self.mu = None\n",
        "    self.sd = None\n",
        "\n",
        "  def fit_transform(self, x):\n",
        "    self.mu = np.mean(x, axis=(0), keepdims=True)\n",
        "    self.sd = np.std(x, axis=(0), keepdims=True)\n",
        "    normalized_x = (x - self.mu) / self.sd\n",
        "    return normilized_x\n",
        "\n",
        "  def inverse_transform(self, x):\n",
        "    return (x * self.sd) + self.mu\n",
        "\n",
        "# normilze\n",
        "scaler = Normalizer()\n",
        "normalized_data_close_price = scaler.fit_transform(data_close_price)"
      ],
      "metadata": {
        "id": "iDo5YJqLcI1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data: generating val and traing datasets\n",
        "def prepare_x(x, window_size):\n",
        "  # perform windowing\n",
        "  n_row = x.shape[0] - window_size + 1\n",
        "  output = np.lib.stride_tricks.as_strided(x, shape=(n_row, window_size), strides = (x.strides[0], x.strides[0]))\n",
        "  return output[:-1], output[-1]\n",
        "\n",
        "def prepare_y(x, window_size):\n",
        "  # perform single moving average\n",
        "  # output = np.convolve(x, np.ones(window_size), 'valid') / window_size\n",
        "\n",
        "  # use the next day as a label\n",
        "  output = x[window_size:]\n",
        "  return output\n",
        "\n",
        "def prepare_data(normalized_data_close_price, config, plot=False):\n",
        "  data_x, data_x_unseen = prepare_x(normalized_data_close_price, window_size=config[\"data\"][\"window_size\"])\n",
        "  data_y = prepare_y(normalized_data_close_price, window_size=config[\"data\"][\"window_size\"])\n",
        "\n",
        "  # split the dataset\n",
        "  split_index = int(data_y.shape[0]*config[\"data\"][\"train_split_size\"])\n",
        "  data_x_train = data_x[:split_index]\n",
        "  data_x_val = data_x[split_index:]\n",
        "  data_y_train = data_y[:split_index]\n",
        "  data_y_val = data_Y[split_index:]\n",
        "\n",
        "  if plot:\n",
        "    # prepare data for plotting\n",
        "    to_plot_data_y_train = np.zeros(num_data_points)\n",
        "    to_plot_data_y_val = np.zeros(num_data_points)\n",
        "\n",
        "    to_plot_data_y_train[config[\"data\"][\"window_state\"]: split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(data_y_train)\n",
        "    to_plot_data_y_val[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(data_y_val)\n",
        "\n",
        "    to_plot_y_train = np.where(to_plot_y_train == 0, None, to_plot_data_y_train)\n",
        "    to_plot_y_val = np.where(to_plot_y_val == 0, None, to_plot_data_y_val)\n",
        "\n",
        "    #plots\n",
        "    fig = figure(figsize=(25,5), dpi=80)\n",
        "    fig.patch.set_color((1.0,1.0,1.0))\n",
        "    plt.plot(data_date, to_plot_data_y_train, label=\"Prices (train)\", color=config[\"plots\"][\"color_train\"])\n",
        "    plt.plot(data_date, to_plot_data_y_val, label=\"Prices (validation)\", color=config[\"plots\"][\"color_val\"])\n",
        "    xticks = [data_date[i] if((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i == num_data_points-1) else None for i in range(num_data_points)]\n",
        "    x = np.arange(0, len(xticks))\n",
        "    plt.xticks(x, xticks, rotation='vertical')\n",
        "    plt.tittle(\"Daily close prices for \" + config[\"alpha_vantage\"][\"symbol\"] + \" - showing training and validation data\")\n",
        "    plt.grid(b=None, witch='major', axis='y', linestyle = '--')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  return split_index, data_x_train, data_y_train, data_x_val, data_y_val, data_x_unseen\n",
        "\n",
        "split_index, data_x_train, data_y_train, data_x_val, data_y_val, data_x_unseen = prepare_data(normalized_data_close_price, config, plot=config[\"plots\"][\"show_plots\"])"
      ],
      "metadata": {
        "id": "0NMCJPkpgXIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    x = np.expand_dims(x, 2)  # we need to make x have the correct shape for LSTM\n",
        "    self.x = x.astype(np.float32)\n",
        "    self.y = y.astype(np.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return (self.x[idx], self.y[ix])\n",
        "\n",
        "dataset_train = TimeSeriesDataset(data_x_train, data_y_train)\n",
        "dataset_val = TimeSeriesDataset(data_x_val, data_y_val)\n",
        "\n",
        "print(\"Training data shape: \", dataset_train.x.shape, dataset_train.y.shape)\n",
        "print(\"Validation data shape: \", dataset_val.x.shape, dataset_val.y.shape)"
      ],
      "metadata": {
        "id": "sKy2lnHJvPJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size=1, hidden_state=32, num_layers=2, output_size=1, dropout=0.2):\n",
        "    super().__init__()\n",
        "    self.hidden_state = hidden_state\n",
        "    self.linear = nn.Linear(input_size, hidden_state)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.lstm = nn.LSTM(hidden_state, hidden_size=self.hidde_state, num_layers=num_layers, batch_first=True)\n",
        "    self.dropout = nn.dropout(dropout)\n",
        "    self.linear2 = nn.Linear(num_layers*hidden_state, output_size)\n",
        "\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    for name, param in self.lstm.named_parameters():\n",
        "      if 'bias' in name:\n",
        "        nn.init_constant_(param, 0.0)\n",
        "      elif 'weight_ih' in name:\n",
        "        nn.init.kaiming_normal_(param)\n",
        "      elif 'weight_hh' in name:\n",
        "        nn.init.orthogonal_(param)\n",
        "\n",
        "  def forward(self ,x):\n",
        "    batchsize = x.shape[0]\n",
        "\n",
        "    x = self.linear1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    # LSTM layer\n",
        "    lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "\n",
        "    # reshape output from hidden cell into [batch, feaure] for linear_2\n",
        "    x = h_n.permute(1,0,2).reshape(batchsize, -1)\n",
        "\n",
        "    # layer2\n",
        "    x = self.dropout(x)\n",
        "    predictions = self.linear2(x)\n",
        "    return predictions[:,-1]\n",
        "\n",
        "model = LSTM(input_size=config[\"model\"][\"input_size\"], hidden_state=config[\"model\"][\"lstm_size\"], num_layers=config[\"model\"][\"num_lstm_layers\"], output_size=1, dropout=config[\"model\"][\"dropout\"])\n",
        "model = model.to(config[\"training\"][\"device\"])"
      ],
      "metadata": {
        "id": "iONQ-76rkWcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(dataloader, is_training=False):\n",
        "  epoch_loss = 0\n",
        "  if is_training: model.train()\n",
        "  else: model.val()\n",
        "  for idx, (x,y) in enumerate(dataloader):\n",
        "    if is_training: optimizer.zero_grad()\n",
        "    batchsize = x.shape[0]\n",
        "\n",
        "    x = x.to(config[\"training\"][\"device\"])\n",
        "    y = y.to(config[\"training\"][\"device\"])\n",
        "\n",
        "    out = model(x)\n",
        "    loss = criterion(out.contiguous(), y.contiguous())\n",
        "\n",
        "    if is_training:\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    epoch_loss += (loss.detatch().item() / batchsize)\n",
        "\n",
        "  lr = scheduler.get_last_lr()[0]\n",
        "  return epoch_loss, lr\n",
        "\n",
        "# create dataloader\n",
        "train_dataloader = DataLoder(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
        "\n",
        "# define optimizer, sheduler and loss function\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=(0.9, 0.98), eps=1e-9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config[\"training\"][\"scheduler_step_size\"], gamma=0.1)\n",
        "\n",
        "# begin training\n",
        "for epoch in range(config[\"training\"][\"num_epoch\"]):\n",
        "  loss_train, lr_train = run_epoch(train_dataloader, is_training=True)\n",
        "  loss_val, lr_val = run_epoch(val_dataloader, is_training=False)\n",
        "  scheduler.step()\n",
        "\n",
        "  print(f'Epoch: {epoch}/{config[\"training\"][\"num_epochs\"]} |  loss_train: {loss_train.6f}')"
      ],
      "metadata": {
        "id": "Uttz8J2feEQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model evaluation\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# predict on the training data, to see how well the model managed to learn\n",
        "predicted_train = np.array([])\n",
        "for idx, (x,y) in enumerate(train_dataloader):\n",
        "  x = x.to(config[\"training\"][\"device\"])\n",
        "  out = model(x)\n",
        "  out = out.cpu().detach().numpy()\n",
        "  predicted_train = np.concatenate((predicted_train, out))\n",
        "\n",
        "predicted_val = np.array([])\n",
        "for idx, (x,y) in enumerate(val_dataloader):\n",
        "  x = x.to(config[\"training\"][\"device\"])\n",
        "  out = model(x)\n",
        "  out = out.cpu().detach().numpy()\n",
        "  predicted_val = np.concatenate((predicted_val, out))\n",
        "\n",
        "if config[\"plots\"][\"show_plots\"]:\n",
        "  # prepare data for plotting, show predicted prices\n",
        "  to_plot_data_y_train_pred = np.zeros(num_data_points)\n",
        "  to_plot_data_y_val_pred = np.zeros(num_data_points)\n",
        "\n",
        "  to_plot_data_y_train_pred[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(predicted_train)\n",
        "  to_plot_data_y_val_pred[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(predicted_val)\n",
        "\n",
        "  to_plot_data_y_train_pred = np.where(to_plot_data_y_train_pred == 0, None, to_plot_data_y_train_pred)\n",
        "  to_plot_data_y_val_pred = np.where(to_plot_data_y_val_pred == 0, None, to_plot_data_y_val_pred)\n",
        "\n",
        "  #plotting\n",
        "  fig = figure(figsize=(25, 5), dpi=80)\n",
        "  fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "  plt.plot(data_date, data_close_price, label=\"Actual prices\", color=config[\"plots\"][\"color_actual\"])\n",
        "  plt.plot(data_date, to_plot_data_y_train_pred, label=\"Predicted prices (train)\", color=config[\"plots\"][\"color_pred_train\"])\n",
        "  plt.plot(data_date, to_plot_data_y_val_pred, label=\"Predicted prices (validation)\", color=config[\"plots\"][\"color_pred_val\"])\n",
        "  plt.title(\"Compare predicted prices to actual prices\")\n",
        "  xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
        "  x = np.arange(0,len(xticks))\n",
        "  plt.xticks(x, xticks, rotation='vertical')\n",
        "  plt.grid(b=None, which='major', axis='y', linestyle='--')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  # prepare data for plotting, zoom in validation\n",
        "\n",
        "  to_plot_data_y_val_subset = scaler.inverse_transform(data_y_val)\n",
        "  to_plot_predicted_val = scaler.inverse_transform(predicted_val)\n",
        "  to_plot_data_date = data_date[split_index+config[\"data\"][\"window_size\"]:]\n",
        "\n",
        "  # plots\n",
        "\n",
        "  fig = figure(figsize=(25, 5), dpi=80)\n",
        "  fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "  plt.plot(to_plot_data_date, to_plot_data_y_val_subset, label=\"Actual prices\", color=config[\"plots\"][\"color_actual\"])\n",
        "  plt.plot(to_plot_data_date, to_plot_predicted_val, label=\"Predicted prices (validation)\", color=config[\"plots\"][\"color_pred_val\"])\n",
        "  plt.title(\"Zoom in to examine predicted price on validation data portion\")\n",
        "  xticks = [to_plot_data_date[i] if ((i%int(config[\"plots\"][\"xticks_interval\"]/5)==0 and (len(to_plot_data_date)-i) > config[\"plots\"][\"xticks_interval\"]/6) or i==len(to_plot_data_date)-1) else None for i in range(len(to_plot_data_date))] # make x ticks nice\n",
        "  xs = np.arange(0,len(xticks))\n",
        "  plt.xticks(xs, xticks, rotation='vertical')\n",
        "  plt.grid(b=None, which='major', axis='y', linestyle='--')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "v--WwNliwPKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting future stock prices\n",
        "model.eval()\n",
        "\n",
        "x = torch.tensor(data_x_unseen).float().to(config[\"training\"][\"device\"]).unsqueeze(0).unsqueeze(2)\n",
        "prediction = model(x)\n",
        "prediction = prediction.cpu().detach().numpy\n",
        "prediction = scaler.inverse_transform(prediction)[0]\n",
        "\n",
        "if config[\"plots\"][\"show_plots\"]:\n",
        "  # prepare plots\n",
        "  plot_range = 10\n",
        "  to_plot_data_y_val = np.zeros(plot_range)\n",
        "  to_plot_data_y_val_pred = np.zeros(plot_range)\n",
        "  to_plot_data_y_train_pred = np.zeros(plot_range)\n",
        "\n",
        "  to_plot_data_y_val[:plot_range-1] = scaler.inverse_transform(data_y_val)[-plot_range+1:]\n",
        "  to_plot_data_y_val_pred[:plot_range-1] = scaler.inverse_transform(predicted_val)[-plot_range+1:]\n",
        "\n",
        "  to_plot_data_y_val_pred = prediction\n",
        "\n",
        "  to_plot_data_y_val = np.where(to_plot_data_y_val == 0, None, to_plot_data_y_val)\n",
        "  to_plot_data_y_val_pred = np.where(to_plot_data_y_val_pred == 0, None, to_plot_data_y_val_pred)\n",
        "  to_plot_data_y_test_pred = np.where(to_plot_data_y_test_pred == 0, None, to_plot_data_y_train_pred)\n",
        "\n",
        "  #plot\n",
        "  plot_data_test = data_date[-plot_range+1]\n",
        "  plot_data_test.append(\"next trading day\")\n",
        "\n",
        "  fig = figure(figsize=(25, 5), dpi=80)\n",
        "  fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "  plt.plot(plot_date_test, to_plot_data_y_val, label=\"Actual prices\", marker=\".\", markersize=10, color=config[\"plots\"][\"color_actual\"])\n",
        "  plt.plot(plot_date_test, to_plot_data_y_val_pred, label=\"Past predicted prices\", marker=\".\", markersize=10, color=config[\"plots\"][\"color_pred_val\"])\n",
        "  plt.plot(plot_date_test, to_plot_data_y_test_pred, label=\"Predicted price for next day\", marker=\".\", markersize=20, color=config[\"plots\"][\"color_pred_test\"])\n",
        "  plt.title(\"Predicted close price of the next trading day\")\n",
        "  plt.grid(b=None, which='major', axis='y', linestyle='--')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "print(\"Predicted close price of the next trading day:\", round(prediction, 2))"
      ],
      "metadata": {
        "id": "ScIthm1iVoSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}